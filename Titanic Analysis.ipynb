{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Predicting Whether Someone Was Likely to Have Survived on the Titanic Based on Class, Age, and Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genevieve Gottlieb <br/>\n",
    "Big Data and Analytics, Lab 4 <br/>\n",
    "11/28/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction: <br/>\n",
    "In this lab I am analyzing a dataset about the people who were on the Titanic when it sank. I predict whether someone was likely to have survived the event based on their class, age, and gender. I also find out what the most important features that determine whether a person died or survived are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "raw_data = open(\"titanic.csv\")\n",
    "dataset = np.loadtxt(raw_data, delimiter = \",\")\n",
    "X = dataset[:,0:3]\n",
    "y = dataset[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average accuracy of the following three machine learning algorithms on this dataset: DecisionTree, KNeighbors, RandomForest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789282470481\n",
      "[0.78655767484105354, 0.80199818346957308, 0.78655767484105354, 0.76385104450499541, 0.77747502270663038, 0.77747502270663038, 0.78019981834695729, 0.78655767484105354, 0.78474114441416898, 0.79836512261580383]\n",
      "0.784377838329\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree:\n",
    "import statistics\n",
    "from sklearn import datasets\n",
    "import random\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "\n",
    "from sklearn import tree\n",
    "tree_classifier = tree.DecisionTreeClassifier();\n",
    "tree_classifier = tree_classifier.fit(X_train, y_train)\n",
    "tree_predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(tree_predictions, y_test))\n",
    "\n",
    "#Finding Average\n",
    "numbers = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "    tree_classifier = tree.DecisionTreeClassifier();\n",
    "    tree_classifier = tree_classifier.fit(X_train, y_train)\n",
    "    tree_predictions = tree_classifier.predict(X_test)\n",
    "    numbers.append(accuracy_score(tree_predictions, y_test))\n",
    "print(numbers)\n",
    "print(statistics.mean(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77838328792\n",
      "[0.73932788374205272, 0.77384196185286103, 0.76566757493188009, 0.58401453224341504, 0.54041780199818346, 0.79473206176203448, 0.77656675749318804, 0.79564032697547682, 0.7829246139872843, 0.76566757493188009]\n",
      "0.731880108992\n"
     ]
    }
   ],
   "source": [
    "#KNeighbors:\n",
    "import statistics\n",
    "from sklearn import neighbors\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "\n",
    "knn_classifier = neighbors.KNeighborsClassifier()\n",
    "knn_classifier = knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(knn_predictions, y_test))\n",
    "\n",
    "#Finding Average\n",
    "numbers = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "    knn_classifier = neighbors.KNeighborsClassifier();\n",
    "    knn_classifier = knn_classifier.fit(X_train, y_train)\n",
    "    knn_predictions = knn_classifier.predict(X_test)\n",
    "    numbers.append(accuracy_score(knn_predictions, y_test))\n",
    "print(numbers)\n",
    "print(statistics.mean(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785649409628\n",
      "[0.79382379654859214, 0.79200726612170758, 0.77838328792007261, 0.76657584014532243, 0.78474114441416898, 0.77747502270663038, 0.77656675749318804, 0.77111716621253401, 0.80199818346957308, 0.76930063578564944]\n",
      "0.781198910082\n"
     ]
    }
   ],
   "source": [
    "#RandomForest:\n",
    "import statistics\n",
    "from sklearn import ensemble\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(rf_predictions, y_test))\n",
    "\n",
    "#Finding Average\n",
    "numbers = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "    rf_classifier = ensemble.RandomForestClassifier();\n",
    "    rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "    rf_predictions = rf_classifier.predict(X_test)\n",
    "    numbers.append(accuracy_score(rf_predictions, y_test))\n",
    "print(numbers)\n",
    "print(statistics.mean(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the most accurate algorithm, predict whether the following imaginary people would have survived: <br/>\n",
    "a. An adult male in the 3rd class <br/>\n",
    "b. An adult female in 1st class <br/>\n",
    "c. A female child in 1st class <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.]\n"
     ]
    }
   ],
   "source": [
    "#RandomForest:\n",
    "from sklearn import ensemble\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict([[3, 1, 1]])\n",
    "print(rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "#RandomForest:\n",
    "from sklearn import ensemble\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict([[1, 1, 0]])\n",
    "print(rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "#RandomForest:\n",
    "from sklearn import ensemble\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict([[1, 0, 0]])\n",
    "print(rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the most important determining feature in this dataset? (Try removing features one at a time, and observe the results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "raw_data = open(\"ClassthenAge.csv\")\n",
    "dataset = np.loadtxt(raw_data, delimiter = \",\")\n",
    "X = dataset[:,0:1]\n",
    "y = dataset[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.690281562216\n",
      "[0.69845594913714804, 0.70481380563124429, 0.71117166212534055, 0.72207084468664851, 0.71026339691189833, 0.71752951861943692, 0.71934604904632149, 0.71389645776566757, 0.72116257947320617, 0.72116257947320617]\n",
      "0.713987284287\n"
     ]
    }
   ],
   "source": [
    "#RandomForest:\n",
    "import statistics\n",
    "from sklearn import ensemble\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(rf_predictions, y_test))\n",
    "\n",
    "#Finding Average\n",
    "numbers = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "    rf_classifier = ensemble.RandomForestClassifier();\n",
    "    rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "    rf_predictions = rf_classifier.predict(X_test)\n",
    "    numbers.append(accuracy_score(rf_predictions, y_test))\n",
    "print(numbers)\n",
    "print(statistics.mean(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "raw_data = open(\"ClassthenSex.csv\")\n",
    "dataset = np.loadtxt(raw_data, delimiter = \",\")\n",
    "X = dataset[:,0:1]\n",
    "y = dataset[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712079927339\n",
      "[0.72388737511353318, 0.70208900999091739, 0.69663941871026336, 0.72207084468664851, 0.72570390554041775, 0.71117166212534055, 0.72661217075386009, 0.70572207084468663, 0.72388737511353318, 0.71752951861943692]\n",
      "0.71553133515\n"
     ]
    }
   ],
   "source": [
    "#RandomForest:\n",
    "import statistics\n",
    "from sklearn import ensemble\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(rf_predictions, y_test))\n",
    "\n",
    "#Finding Average\n",
    "numbers = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "    rf_classifier = ensemble.RandomForestClassifier();\n",
    "    rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "    rf_predictions = rf_classifier.predict(X_test)\n",
    "    numbers.append(accuracy_score(rf_predictions, y_test))\n",
    "print(numbers)\n",
    "print(statistics.mean(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "raw_data = open(\"AgethenSex.csv\")\n",
    "dataset = np.loadtxt(raw_data, delimiter = \",\")\n",
    "X = dataset[:,0:1]\n",
    "y = dataset[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684831970936\n",
      "[0.67393278837420523, 0.67847411444141692, 0.6830154405086285, 0.6830154405086285, 0.65031789282470487, 0.66757493188010897, 0.68664850136239786, 0.6802906448683016, 0.69118982742960944, 0.69482288828337879]\n",
      "0.678928247048\n"
     ]
    }
   ],
   "source": [
    "#RandomForest:\n",
    "import statistics\n",
    "from sklearn import ensemble\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(rf_predictions, y_test))\n",
    "\n",
    "#Finding Average\n",
    "numbers = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "    rf_classifier = ensemble.RandomForestClassifier();\n",
    "    rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "    rf_predictions = rf_classifier.predict(X_test)\n",
    "    numbers.append(accuracy_score(rf_predictions, y_test))\n",
    "print(numbers)\n",
    "print(statistics.mean(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a conclusion - what did you learn overall? What are you still wondering about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I learned quite a few things about coding and specifics about the Titanic. I found that with this particular dataset the most accurate maching learning algorithm is random forest. The decision tree is second most accurate, and kneighbors least. For some reason I though decision tree would be the best prior to this lab, which was an unsubstantiated guess, and was proven wrong. When testing whether a person would die or survive based on their class, age, and sex, I found that an adult male in the third class would die, an adult female in first class would survive, and a female child in first class would survive. This was interesting, and does make sense in the thinking in the movie. Figuring out what feature is most important in determing whether a person dies or survives was interesting, and my hypothesis was justified! Class and sex matters the most. I liked this lab because the Titanic is an interesting subject that we've all learned about or have seen the movie, and it's fun seeing what type of person dies and survives. Also seeing the feature that matters the most was very interesting. Could be helpful to know in other problems like this in the future. One thing I am still wondering about, is how one would go about finding out what feature is the most important, without messing around with the Excel file. That seems like a process beginners take, and there may actually be code in order to do this. Overall, this was an educating lab, and I enjoyed it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: <br/>\n",
    "0- Class (0 = crew, 1 = first, 2 = second, 3 = third) <br/>\n",
    "1- Age (1 = adult, 0 = child) <br/>\n",
    "2- Sex (1 = male, 0 = female) <br/>\n",
    "3- Survived (1 = yes, 0 = no)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
